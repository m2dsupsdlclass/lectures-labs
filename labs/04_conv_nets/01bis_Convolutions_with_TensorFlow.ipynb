{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "## Run this cell once before the lab to download\n",
    "## the mnist dataset and the pre-trained ResNet50 model. \n",
    "\n",
    "## Mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "## Keras pre-trained weights\n",
    "from keras.utils.data_utils import get_file\n",
    "get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "         'https://github.com/fchollet/deep-learning-models/releases'+\n",
    "         '/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "         cache_subdir='models',\n",
    "         md5_hash='a7b3fe01876f51b976af0dea6bc144eb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "Objectives:\n",
    "- TensorFlow tutorial\n",
    "- Application of convolution on images\n",
    "- First conv net on MNIST with TensorFlow\n",
    "- Use a pre-trained ResNet with Keras for transfer learning (second notebook)\n",
    "\n",
    "Home assignment: fine-tuning a resnet on GPU (third notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorFlow 101\n",
    "\n",
    "TensorFlow is a symbolic graph computation engine, that allows automatic differentiation of each node\n",
    "- https://www.tensorflow.org \n",
    "- https://www.tensorflow.org/tutorials/mnist/tf/\n",
    "\n",
    "TensorFlow builds where nodes may be:\n",
    "- **constant:** constants tensors, such as a learning rate\n",
    "- **Variables:** any tensor, such as parameters of the models\n",
    "- **Placeholders:** placeholders for inputs and outputs of your models\n",
    "- many other types of nodes (functions, loss, ...)\n",
    "\n",
    "The graph is symbolic, no computation is performed until a `Session` is defined and the command `run` or `eval` is invoked. TensorFlow may run this computation on (multiple) CPUs or GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(3)\n",
    "b = tf.constant(2)\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(type(c))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    c_value = sess.run(c)\n",
    "    \n",
    "print(type(c_value))\n",
    "print(c_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = tf.Variable(0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(d))\n",
    "\n",
    "    sess.run(d.assign_add(c))\n",
    "    print(sess.run(d))\n",
    "\n",
    "    sess.run(d.assign_add(c))\n",
    "    print(sess.run(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Input placeholders\n",
    "\n",
    "- The placeholder is a variable that doesn't have a value yet in the symbolic graph. The value will be fed when running the session by passing the `feed_dict` argument\n",
    "- If the placeholder is a k-dimensional tensor, we need to specify its shape. \n",
    "- It is possible to leave the shape variable by putting `None` values in the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float32\", name=\"input\")\n",
    "y = x + tf.constant(3.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = tf.placeholder(\"float32\", shape=(1, 2, 3), name=\"input\")\n",
    "inverted_image = 255. - img\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    fake_img = np.zeros(shape=(1, 2, 3))\n",
    "    print(sess.run(inverted_image, feed_dict={img:fake_img}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img = tf.placeholder(\"float32\", shape= [None, None, 3], name=\"input\")\n",
    "inverted_image = 255. - img\n",
    "with tf.Session() as sess:\n",
    "    fake_img = np.zeros(shape=(3, 2, 3))\n",
    "    print(sess.run(inverted_image, feed_dict={img:fake_img}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reading and opening images\n",
    "\n",
    "The following code enables to read an image, put it in a numpy array and display it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_image = imread(\"bumblebee.png\")\n",
    "sample_image= sample_image.astype(float)\n",
    "\n",
    "size = sample_image.shape\n",
    "print(\"sample image shape: \"+ str(sample_image.shape))\n",
    "\n",
    "def show(image):\n",
    "    image = np.squeeze(image.astype(\"uint8\"))\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "show(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A simple convolution filter\n",
    "\n",
    "The goal of this section to use TensorFlow to perform convolutions on images. This section does not involve training any model yet.\n",
    "\n",
    "We build a convolution filter that blurs the image using `tf.nn.depthwise_conv2d` (treats each channel separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image = tf.placeholder(tf.float32, shape=(None, None, None, 3))\n",
    "kernel = tf.placeholder(tf.float32, shape=(5, 5, 3))\n",
    "\n",
    "def conv(x, k):\n",
    "    k = tf.reshape(k, shape=(5, 5, 3, 1))\n",
    "    return tf.nn.depthwise_conv2d(x, k, strides=(1, 1, 1, 1),\n",
    "                                  padding='SAME')\n",
    "    \n",
    "output_image = conv(image, kernel)\n",
    "kernel_data = np.zeros(shape=(5, 5, 3)).astype(np.float32)\n",
    "kernel_data[:, :, :] = 1 / 25\n",
    "\n",
    "# move the channel dimension to the first dimension to\n",
    "# make it easy to see the spacial organization of the kernel\n",
    "# on the last 2 dimensions with print:\n",
    "print(np.transpose(kernel_data, (2, 0, 1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    feed_dict = {image: [sample_image], kernel: kernel_data}\n",
    "    conv_img = sess.run(output_image, feed_dict=feed_dict)\n",
    "    print(conv_img.shape)\n",
    "    show(conv_img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise**\n",
    "- Build an identity 3x3 kernel with stride 2. What is the size of the output image?\n",
    "- Change the padding to 'VALID'. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/strides_padding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert image to greyscale\n",
    "grey_sample_image = sample_image.sum(axis=2) / 3.\n",
    "\n",
    "# add the channel dimension even if it's only one channel\n",
    "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
    "\n",
    "show(grey_sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise**\n",
    "- Build an edge detector using `tf.nn.conv2d` on greyscale image\n",
    "- You may experiment with several kernels to find a way to detect edges\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "\n",
    "Try `tf.nn.conv2d?` or press `shift-tab` to get the documentation. You may get help at https://www.tensorflow.org/api_docs/python/nn/convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/edge_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pooling and strides with convolutions\n",
    "\n",
    "**Exercise**\n",
    "- Use `tf.nn.max_pool` to apply a 2x2 max pool to the image\n",
    "- Use `tf.nn.avg_pool` to apply an average pooling.\n",
    "- Is it possible to compute a max pooling and an average pooling with well chosen kernels?\n",
    "\n",
    "**bonus**\n",
    "- Implement a 3x3 average pooling with a regular convolution `tf.nn.conv2d`, with well chosen strides, kernel and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/average_as_conv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building a network on MNIST\n",
    "\n",
    "https://www.tensorflow.org/tutorials/mnist/pros/\n",
    "\n",
    "- Using Tensorflow\n",
    "- Training data preprocessed\n",
    "- Include regularization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A simple feedforward model in TensorFlow \n",
    "\n",
    "- A logistic regression without taking into account the spatiality of the data\n",
    "- Very similar to lab01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MNIST is 28x28 = 784 dimensions\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y_pred = tf.matmul(x,W) + b\n",
    "\n",
    "# We don't have to do the softmax ourselves, TensorFlow can use\n",
    "# logits directly to compute the loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize weights\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Train loop\n",
    "    for i in range(1000):\n",
    "        # mnist.train helper function builds a batch of N elements\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        train_step.run(feed_dict={x: batch[0], y_true: batch[1]})\n",
    "        \n",
    "    feed_dict={x: mnist.test.images, \n",
    "               y_true: mnist.test.labels}\n",
    "    print(accuracy.eval(feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CNN model in TensorFlow\n",
    "\n",
    "You are going to build a convolutional neural network with TensorFlow.\n",
    "\n",
    "The following helper functions were taken from TensorFlow tutorial https://www.tensorflow.org/tutorials/mnist/pros/\n",
    "\n",
    "They allow:\n",
    "- to define weights and bias by only specifying the shape\n",
    "- easy use of convolutions and max_pool layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to use the spatial geometry of the image, we reshape the input tensor to (`batch_size, 28, 28, channel_number`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# only 1 channel (grey image) and the batch size is -1 because\n",
    "# we don't know its size beforehand\n",
    "x_image = tf.reshape(x, (-1, 28, 28, 1))\n",
    "print(x_image.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    batch = mnist.train.next_batch(10)\n",
    "    x_value, x_image_value = sess.run(\n",
    "        [x, x_image], feed_dict={x: batch[0]})\n",
    "    \n",
    "    print(x_value.shape, x_image_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convolution layer example in TensorFlow\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "h_conv1 = conv2d(x_image, W_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch = mnist.train.next_batch(10)\n",
    "    output_conv, output_pool = sess.run(\n",
    "        [h_conv1, h_pool1], feed_dict={x: batch[0]})\n",
    "    \n",
    "    print(\"conv activation shape:\", output_conv.shape)\n",
    "    print(\"pool activation shape:\", output_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Exercise **\n",
    "\n",
    "Build a CNN with the following architecture:\n",
    "- Convolution 5x5, 32 output channels + bias\n",
    "- ReLU (you may use `tf.nn.relu`)\n",
    "- Maxpool 2x2\n",
    "- Convolution 5x5, 64 output channels + bias\n",
    "- ReLU\n",
    "- Maxpool 2x2\n",
    "- Fully connected layer of size 1024 (you may use `tf.reshape(x, [-1, size])`)\n",
    "- ReLU\n",
    "- Output fully connected layer of size 10 \n",
    "- The output should be named `y_conv`\n",
    "\n",
    "**Bonus** add dropout\n",
    "- A 50% dropout should work here\n",
    "- You may use `tf.nn.dropout(x, keep_prob)`\n",
    "- You should add keep prob as an input of the model, and pass 0.5 during training and 1.0 during test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/mnist_conv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# softmax and loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_true)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(500):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0:\n",
    "            feed_dict = {x:batch[0], y_true: batch[1]}\n",
    "            train_accuracy = accuracy.eval(feed_dict=feed_dict)\n",
    "            print(\"step %d, training accuracy %g\"\n",
    "                  % (i, train_accuracy))\n",
    "        feed_dict = {x: batch[0], y_true: batch[1]}\n",
    "        train_step.run(feed_dict = feed_dict)\n",
    "        \n",
    "    feed_dict = {x: mnist.test.images[:1000],\n",
    "                 y_true: mnist.test.labels[:1000]}\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%load solutions/mnist_conv_dropout.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
