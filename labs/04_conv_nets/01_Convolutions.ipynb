{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "\n",
    "Objectives:\n",
    "- Application of convolution on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and opening images\n",
    "\n",
    "The following code enables to read an image, put it in a numpy array and display it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = imread(\"bumblebee.png\")\n",
    "sample_image= sample_image.astype(\"float32\")\n",
    "\n",
    "size = sample_image.shape\n",
    "print(\"sample image shape: \", sample_image.shape)\n",
    "\n",
    "plt.imshow(sample_image.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple convolution filter\n",
    "\n",
    "The goal of this section to use tensorflow / Keras to perform individual convolutions on images. This section does not involve training any model yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "              input_shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: in Keras, `None` is used as a marker for tensor dimensions with dynamic size. In this case `batch_size`, `width` and `height` are all dynamic: they can depend on the input. Only the number of input channels (3 colors) has been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = np.expand_dims(sample_image, 0)\n",
    "img_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**: \n",
    "\n",
    "\n",
    "If we apply this convolution to this image, what will be the shape of the generated feature map?\n",
    "\n",
    "Hints:\n",
    "\n",
    "- in Keras `padding=\"same\"` means that convolutions uses as much padding as necessary so has to preserve the spatial dimension of the input maps or image;\n",
    "\n",
    "- in Keras, convolutions have no strides by default.\n",
    "\n",
    "Bonus: how much padding Keras has to use to preserve the spatial dimensions in this particular case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = conv(img_in)\n",
    "print(type(img_out), img_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a tensorflow Eager Tensor, which can be converted to obtain a standard numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img_out = img_out[0].numpy()\n",
    "print(type(np_img_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(sample_image.astype('uint8'))\n",
    "ax1.imshow(np_img_out.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has 3 channels, hence can also be interpreted as an RGB image with matplotlib. However it is the result of a random convolutional filter applied to the original one.\n",
    "\n",
    "\n",
    "Let's look at the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: can you compute the number of trainable parameters from the layer hyperparameters?\n",
    "\n",
    "Hints:\n",
    "\n",
    "- the input image has 3 colors and a single **convolution kernel** mixes information from all the three input channels to compute its output;\n",
    "\n",
    "- a **convolutional layer** outputs many channels at once: each channel is the output of a distinct convolution operation (aka unit) of the layer;\n",
    "\n",
    "- do not forget the biases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: let's introspect the keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conv.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = conv.get_weights()[0]\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eeach of the 3 output channels is generated by a distinct convolution kernel.\n",
    "\n",
    "Each convolution kernel has a spatial size of 5x5 and operates across 3 input channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = conv.get_weights()[1]\n",
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One bias per output channel.\n",
    "\n",
    "We can instead build a kernel ourselves, by defining a function which will be passed to `Conv2D` Layer.\n",
    "We'll create an array with 1/25 for filters, with each channel seperated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape=(5, 5, 3, 3), dtype=None):\n",
    "    array = np.zeros(shape=shape, dtype=\"float32\")\n",
    "    array[:, :, 0, 0] = 1 / 25\n",
    "    array[:, :, 1, 1] = 1 / 25\n",
    "    array[:, :, 2, 2] = 1 / 25\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the numpy filters by moving the spatial dimensions in the end (using `np.transpose`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(my_init(), (2, 3, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv = Conv2D(filters=3, kernel_size=(5, 5), padding=\"same\",\n",
    "           input_shape=(None, None, 3), kernel_initializer=my_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax0.imshow(img_in[0].astype('uint8'))\n",
    "\n",
    "img_out = conv(img_in)\n",
    "np_img_out = img_out[0].numpy()\n",
    "ax1.imshow(np_img_out.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Define a Conv2D layer with 3 filters (5x5) that compute the identity function (preserve the input image without mixing the colors).\n",
    "- Change the stride to 2. What is the size of the output image?\n",
    "- Change the padding to 'VALID'. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/strides_padding.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on edge detection on Grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert image to greyscale\n",
    "grey_sample_image = sample_image.mean(axis=2)\n",
    "\n",
    "# add the channel dimension even if it's only one channel so\n",
    "# as to be consistent with Keras expectations.\n",
    "grey_sample_image = grey_sample_image[:, :, np.newaxis]\n",
    "\n",
    "\n",
    "# matplotlib does not like the extra dim for the color channel\n",
    "# when plotting gray-level images. Let's use squeeze:\n",
    "plt.imshow(np.squeeze(grey_sample_image.astype(np.uint8)),\n",
    "           cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- Build an edge detector using `Conv2D` on greyscale image\n",
    "- You may experiment with several kernels to find a way to detect edges\n",
    "- https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "\n",
    "Try `Conv2D?` or press `shift-tab` to get the documentation. You may get help at https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/edge_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling and strides with convolutions\n",
    "\n",
    "**Exercise**\n",
    "- Use `MaxPool2D` to apply a 2x2 max pool with strides 2 to the image. What is the impact on the shape of the image?\n",
    "- Use `AvgPool2D` to apply an average pooling.\n",
    "- Is it possible to compute a max pooling and an average pooling with well chosen kernels?\n",
    "\n",
    "**Bonus**\n",
    "- Implement a 3x3 average pooling with a regular convolution `Conv2D`, with well chosen strides, kernel and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pooling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/average_as_conv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
