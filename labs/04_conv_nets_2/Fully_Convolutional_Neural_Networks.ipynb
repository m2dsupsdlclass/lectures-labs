{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fully Convolutional Neural Networks\n",
    "\n",
    "Objectives:\n",
    "- Load a CNN model pre-trained on ImageNet\n",
    "- Transform the network into a Fully Convolutional Network \n",
    "- Apply the network perform weak segmentation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet50\n",
    "# We use include_top = False for now,\n",
    "# as we'll import output Dense Layer later\n",
    "\n",
    "from tensorflow.contrib import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(include_top=False)\n",
    "\n",
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res5c = base_model.layers[-2]\n",
    "type(res5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res5c.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "avg_pool = base_model.layers[-1]\n",
    "type(avg_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "avg_pool.pool_size, avg_pool.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "avg_pool.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully convolutional ResNet\n",
    "\n",
    "- Out of the `res5c` residual block, the resnet outputs a tensor of shape $W \\times H \\times 2048$. \n",
    "- For the default ImageNet input, $224 \\times 224$, the output size is $7 \\times 7 \\times 2048$\n",
    "- After this bloc, the ResNet uses an average pooling `AveragePooling2D(pool_size=(7, 7))` with `(7, 7)` strides which divides by 7 the width and height\n",
    "\n",
    "#### Regular ResNet layers \n",
    "\n",
    "The regular ResNet head after the base model is as follows: \n",
    "```py\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1000)(x)\n",
    "x = Softmax()(x)\n",
    "```\n",
    "\n",
    "Here is the full definition of the model: https://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\n",
    "\n",
    "#### Our Version\n",
    "\n",
    "- To keep spatial information as much as possible, we will remove the average pooling.\n",
    "- We want to retrieve the labels information, which is stored in the Dense layer. We will load these weights afterwards\n",
    "- We will change the Dense Layer to a Convolution2D layer to keep spatial information, to output a $W \\times H \\times 1000$.\n",
    "- We can use a kernel size of (1, 1) for that new Convolution2D layer to pass the spatial organization of the previous layer unchanged.\n",
    "- We want to apply a softmax only on the last dimension so as to preserve the $W \\times H$ spatial information.\n",
    "\n",
    "#### A custom Softmax\n",
    "\n",
    "We build the following Custom Layer to apply a softmax only to the last dimension of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "# A custom layer in Keras must implement the four following methods:\n",
    "class SoftmaxMap(Layer):\n",
    "    # Init function\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "        self.axis = axis\n",
    "        super(SoftmaxMap, self).__init__(**kwargs)\n",
    "\n",
    "    # There's no parameter, so we don't need this one\n",
    "    def build(self,input_shape):\n",
    "        pass\n",
    "\n",
    "    # This is the layer we're interested in: \n",
    "    # very similar to the regular softmax but note the additional\n",
    "    # that we accept x.shape == (batch_size, w, h, n_classes)\n",
    "    # which is not the case in Keras by default.\n",
    "    def call(self, x, mask=None):\n",
    "        e = K.exp(x - K.max(x, axis=self.axis, keepdims=True))\n",
    "        s = K.sum(e, axis=self.axis, keepdims=True)\n",
    "        return e / s\n",
    "\n",
    "    # The output shape is the same as the input shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check that we can use this layer to normalize the classes probabilities of some random spatial predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_samples, w, h, n_classes = 10, 3, 4, 5\n",
    "random_data = np.random.randn(n_samples, w, h, n_classes)\n",
    "random_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because those predictions are random, if we some accross the classes dimensions we get random values instead of class probabilities that would need to some to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "random_data[0].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's wrap the `SoftmaxMap` class into a test model to process our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([SoftmaxMap(input_shape=(w, h, n_classes))])\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax_mapped_data = model.predict(random_data)\n",
    "softmax_mapped_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The last dimension now approximately sum to one, we can therefore be used as class probabilities (or parameters for a multinouli distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax_mapped_data[0].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Exercise **\n",
    "- What is the shape of the convolution kernel we want to apply to replace the Dense ?\n",
    "- Build the fully convolutional model as described above.\n",
    "- You may introspect the last elements of `base_model.layers` to find which layer to remove\n",
    "- You may use the Keras `Convolution2D(output_channels, filter_w, filter_h)` layer and our `SotfmaxMap` to normalize the result as per-class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Model\n",
    "\n",
    "input = base_model.layers[0].input\n",
    "\n",
    "# TODO: compute per-area class probabilites\n",
    "output = input\n",
    "\n",
    "fully_conv_ResNet = Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/fully_conv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can use the following random data to check that it's possible to run a forward pass on a random RGB image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction_maps = fully_conv_ResNet.predict(np.random.randn(1, 200, 300, 3))\n",
    "prediction_maps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How do you explain the resulting output shape?\n",
    "\n",
    "The class probabilities should sum to one in each area of the output map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction_maps.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading Dense weights\n",
    "\n",
    "- We provide the weights and bias of the last Dense layer of ResNet50 in file `weights_dense.h5`\n",
    "- Our last layer is now a 1x1 convolutional layer instead of a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('weights_dense.h5','r')\n",
    "w = h5f['w'][:]\n",
    "b = h5f['b'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "last_layer = fully_conv_ResNet.layers[-2]\n",
    "\n",
    "print(\"Loaded weight shape:\", w.shape)\n",
    "print(\"Last conv layer weights shape:\", last_layer.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reshape the weights\n",
    "w_reshaped = w.reshape((1, 1, 2048, 1000))\n",
    "\n",
    "# set the conv layer weights\n",
    "last_layer.set_weights([w_reshaped, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A forward pass\n",
    "\n",
    "- We define the following function to test our new network. \n",
    "- It resizes the input to a given size, then uses `model.predict` to compute the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def forward_pass_resize(img_path, img_size):\n",
    "    img_raw = imread(img_path)\n",
    "    print(\"img shape before resizing: %s\" % (img_raw.shape,))\n",
    "    img = imresize(img_raw, size=img_size).astype(\"float32\")\n",
    "    img = preprocess_input(img[np.newaxis])\n",
    "    print(\"img batch size shape before forward pass:\", img.shape)\n",
    "    z = fully_conv_ResNet.predict(img)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = forward_pass_resize(\"dog.jpg\", (800, 600))\n",
    "print(\"prediction map shape\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Finding dog-related classes\n",
    "ImageNet uses an ontology of concepts, from which classes are derived. A synset corresponds to a node in the ontology.\n",
    "\n",
    "For example species of dogs are children nodes of the synset `dog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper file for importing synsets from imagenet\n",
    "import imagenet_tool\n",
    "synset = \"n02084071\" # synset corresponding to dogs\n",
    "ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "print(\"All dog classes ids (%d):\" % len(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for dog_id in ids[:10]:\n",
    "    print(imagenet_tool.id_to_words(dog_id))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Unsupervised heatmap of the class \"dog\"\n",
    "\n",
    "The following function builds a heatmap from a forward pass. It sums the representation for all ids corresponding to a synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_heatmap(z, synset):\n",
    "    ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "    ids = np.array([id_ for id_ in ids if id_ is not None])\n",
    "    x = z[0, :, :, ids].sum(axis=0)\n",
    "    print(\"size of heatmap: \" + str(x.shape))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display_img_and_heatmap(img_path, heatmap):\n",
    "    dog = imread(img_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(dog)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(heatmap, interpolation='nearest', cmap=\"viridis\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Exercise**\n",
    "- What is the size of the heatmap compared to the input image?\n",
    "- Build 3 dog heatmaps from `\"dog.jpg\"`, with the following sizes:\n",
    "  - `(400, 640)`\n",
    "  - `(800, 1280)`\n",
    "  - `(1600, 2560)`\n",
    "- What do you observe? \n",
    "\n",
    "You may plot a heatmap using the above function `display_img_and_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dog synset\n",
    "s = \"n02084071\"\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/build_heatmaps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Combining the 3 heatmaps\n",
    "By combining the heatmaps at different scales, we obtain a much better information about the location of the dog.\n",
    "\n",
    "**Bonus**\n",
    "- Combine the three heatmap by resizing them to a similar shape, and averaging them\n",
    "- A geometric norm will work better than standard average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/geom_avg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Bonus**\n",
    "\n",
    "Train the parameters of the last Convolution / classification layer of this segmentation network on classes of your choice on the MS COCO 2016 dataset:\n",
    "\n",
    "http://mscoco.org/dataset/#overview\n",
    "\n",
    "- Use the GPU to precompute the activations of a headless and convolutionalized ResNet50 or Xception model;\n",
    "- Initialize the weights of a new Convolution2D(n_classes, 1, 1) at random;\n",
    "- Train the top of the segmentation model on class label data extracted from the  MS COCO 2016 dataset;\n",
    "- Start with a single low resolution model. Then add multi-scale and see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
